{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83d26149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import obspy\n",
    "import obspy.signal.filter\n",
    "from obspy import UTCDateTime\n",
    "from pnwstore.mseed import WaveformClient\n",
    "client = WaveformClient()\n",
    "import datetime\n",
    "import scipy\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ef227d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/koepflma/project1/Mt-St-Helens')\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f4b5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_noise(year, jday):\n",
    "    \n",
    "    # define some parameters------------------------------------------------------------------------------------------------------\n",
    "    # station parameters\n",
    "    net = 'UW'\n",
    "    sta = 'SHW'\n",
    "    cha = 'EHZ'\n",
    "    \n",
    "    # instrument response parameters\n",
    "    pre_filt = [1e-2, 5e-2, 45, 50]\n",
    "    water_level = 60\n",
    "    \n",
    "    # time windows\n",
    "    win_len = 2**16 # number of points in window\n",
    "    win_overlap = 0 # number of overlapping points\n",
    "    min_am = 0.8 # minimal amount of datapoints in sliced trace to take trace into acount\n",
    "    \n",
    "    # saving array\n",
    "    save_path = 'first_test/{}/{}'.format(year,sta) # path where to save file\n",
    "    save_filename = '{}_{}_{}'.format(year, jday, sta) # file name\n",
    "    \n",
    "    # read in stream--------------------------------------------------------------------------------------------------------------\n",
    "    try:\n",
    "        st_r = read_stream(net, sta, cha, year, jday)\n",
    "    except:\n",
    "#        print('Problem during reading mseed to stream: {}-{}'.format(year,day))\n",
    "        return # continue with next day, everything below is skipped\n",
    "        \n",
    "    st = st_r#.copy() # no copy due to memory\n",
    "    \n",
    "    # correct insrument response--------------------------------------------------------------------------------------------------\n",
    "    inv = obspy.read_inventory('/auto/pnwstore1-wd11/PNWStationXML/{}/{}.{}.xml'.format(net,net,sta))\n",
    "    for tr in st:\n",
    "        s_time_str = str(tr.stats['starttime']).split('.')[0].replace(':', '-')\n",
    "        tr.remove_response(inventory=inv, zero_mean=True,taper=True, taper_fraction=0.05,\n",
    "                              pre_filt=pre_filt, output=\"VEL\", water_level=water_level,\n",
    "                              plot=False)\n",
    "#                               plot='sensor_response_tests/{}__pre_filt{}-{}_{}-{}__water_level{}.png'.format(\n",
    "#                               s_time_str,\n",
    "#                               pre_filt[0], pre_filt[1], pre_filt[2], pre_filt[3], water_level))\n",
    "    \n",
    "    \n",
    "    # calculate PSD---------------------------------------------------------------------------------------------------------------\n",
    "    Pxx_list =  [] # initialize list\n",
    "    # calculate psd for long enought traces and weight the trace depending on the length of the trace\n",
    "    for tr in st:\n",
    "        if len(tr.data) >= win_len: # trace is as long or longer as window length\n",
    "            try:\n",
    "                Pxx, freqs = matplotlib.mlab.psd(tr.data, NFFT=win_len, noverlap=win_overlap, Fs=st[0].stats.sampling_rate) # PSD\n",
    "                Pxx = Pxx[(freqs>1e-1) & (freqs<2e1)] # save only between 0.1-20Hz\n",
    "                Pxx_list.append(Pxx)\n",
    "#                print(Pxx.shape, freqs.shape, len(Pxx_list))\n",
    "            except:\n",
    "#                print('Long trace, but problems during psd calculations: {}'. format(tr))\n",
    "                pass\n",
    "        else: # trace is shorter than window length\n",
    "#            print('Short trace: {}'. format(tr))\n",
    "            pass\n",
    "\n",
    "    # calculate mean PSD over one day between traces\n",
    "    Pxx = np.mean(Pxx_list, axis=0)\n",
    "    freqs = freqs[(freqs>1e-1) & (freqs<2e1)] # save only between 0.1-20Hz\n",
    "    \n",
    "    # create array with starttimes for one day (UTCDateTime)----------------------------------------------------------------------\n",
    "    start_times = np.arange(UTCDateTime(st[0].stats['starttime'].date), # midnight of start day (UTCDateTime)\n",
    "                            UTCDateTime(st[0].stats['starttime'].date)+60*60*24, # midnight of next day (UTCDateTime)\n",
    "                            (win_len-win_overlap)/st[0].stats['sampling_rate'])[:-1] # time steps in seconds\n",
    "            \n",
    "            \n",
    "    # merge traces within a stream------------------------------------------------------------------------------------------------\n",
    "    st_merge = st.copy()\n",
    "    tr_merge = st_merge.merge()[0]\n",
    "\n",
    "    # initialize lists------------------------------------------------------------------------------------------------------------\n",
    "    rms_list = []\n",
    "    rmes_list = []\n",
    "    pgv_list = []\n",
    "    pga_list = []\n",
    "\n",
    "    # Calculate RMS, RMeS, PGV and PGA--------------------------------------------------------------------------------------------\n",
    "    # loop over starttimes within one day\n",
    "    for s_time in start_times:\n",
    "\n",
    "        # try to cut the trace and calculate RMS, RMeS, PGV and PGA\n",
    "        try:\n",
    "            tr_cut = tr_merge.slice(s_time, s_time + win_len/tr.stats['sampling_rate']) # win_len in sec\n",
    "            tr_cut = tr_cut.data\n",
    "\n",
    "            # if trace is long enought calculate RMS, RMeS, PGV and PGA\n",
    "            if len(tr_cut) >= min_am*win_len:\n",
    "                rms = np.sqrt(np.mean(tr_cut**2))\n",
    "                rmes = np.sqrt(np.median(tr_cut**2))\n",
    "                pgv = max(abs(tr_cut))\n",
    "\n",
    "                tr_acc = (tr_cut.copy()[:-1] - tr_cut.copy()[1:]) /tr.stats['delta']\n",
    "                pga = max(abs(tr_acc))\n",
    "\n",
    "            else:\n",
    "#                print('Trace too short: {}'.format(tr_cut))\n",
    "                rms = np.nan\n",
    "                rmes = np.nan\n",
    "                pgv = np.nan\n",
    "                pga = np.nan\n",
    "\n",
    "            # append RMS, RMeS, PGV and PGA to list\n",
    "            rms_list.append(rms)\n",
    "            rmes_list.append(rmes)\n",
    "            pgv_list.append(pgv)\n",
    "            pga_list.append(pga)   \n",
    "\n",
    "        except:\n",
    "#            print('Problem at starttime: {}'.format(s_time))\n",
    "            pass\n",
    "            \n",
    "    # convert lists into arrays---------------------------------------------------------------------------------------------------\n",
    "#     rms_ar = np.array(rms_list)\n",
    "#     rmes_ar = np.array(rmes_list)\n",
    "#     pgv_ar = np.array(pgv_list)\n",
    "#     pga_ar = np.array(pga_list)\n",
    "\n",
    "#     day_ar = np.array([freqs, Pxx, start_times, rms_ar, rmes_ar, pgv_ar, pga_ar])\n",
    "    day_ar = np.array([freqs, Pxx, start_times, rms_list, rmes_list, pgv_list, pga_list])\n",
    "\n",
    "\n",
    "    # initialize save path and save array-----------------------------------------------------------------------------------------\n",
    "    if not os.path.exists(save_path): # create folders from save_path if not exists\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "    save_nparray(save_path, save_filename, day_ar) # save array\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95033743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2018_1_SHW done\n",
      "20.366400957107544\n",
      "2\n",
      "2018_2_SHW done\n",
      "13.65083909034729\n",
      "3\n",
      "2018_3_SHW done\n",
      "8.768551588058472\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for day in range(1,4):\n",
    "    print(day)\n",
    "    start_tt = time.time()\n",
    "    main_noise(year=2018, jday=day)\n",
    "    stop_tt = time.time()\n",
    "    duration = stop_tt-start_tt\n",
    "    print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21edf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
