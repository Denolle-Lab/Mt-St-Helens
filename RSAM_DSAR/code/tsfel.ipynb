{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc70ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b18187d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import obspy\n",
    "import obspy.signal.filter\n",
    "import datetime\n",
    "import scipy\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import scipy as sc\n",
    "import time\n",
    "import tsfel\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61b016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append(\"/data/wsd01/pnwstore/\")\n",
    "from pnwstore.mseed import WaveformClient\n",
    "client = WaveformClient()\n",
    "\n",
    "# Define all functions---------------------------------------------------\n",
    "\n",
    "def preprocessing(year,jday, net, sta, cha):\n",
    "\n",
    "    try:\n",
    "        # this stream will be used for RSAM and DSAR calculations\n",
    "        #st = obspy.read('/1-fnp/pnwstore1/p-wd05/PNW2004/UW/2004/{}/EDM.UW.2004.{}'.format(jday,jday))\n",
    "        st = client.get_waveforms(network=net, station=sta, channel=cha,\n",
    "                                       year='{}'.format(year), doy='{}'.format(jday))\n",
    "\n",
    "        st.detrend('linear')\n",
    "        st.taper(max_percentage=None,max_length=5, type='hann') #max_length in sec\n",
    "        \n",
    "        # correct insrument response\n",
    "        inv = obspy.read_inventory('/auto/pnwstore1-wd11/PNWStationXML/{}/{}.{}.xml'.format(net,net,sta))\n",
    "        pre_filt = [1e-3, 5e-2, 45, 50]\n",
    "        water_level = 60\n",
    "        \n",
    "        for tr in st:\n",
    "            tr.remove_response(inventory=inv, zero_mean=True,taper=True, taper_fraction=0.05,\n",
    "                                      pre_filt=pre_filt, output=\"VEL\", water_level=water_level,\n",
    "                                      plot=False)\n",
    "\n",
    "            # correct positive dip\n",
    "            dip = inv.get_orientation(tr.id, datetime=tr.stats.starttime)['dip']\n",
    "            if dip > 0:\n",
    "                tr.data *= -1\n",
    "#         st.merge(fill_value=0)\n",
    "        print(':) year={}, jday={}, net={}, sta={}, cha={}'.format(year,jday, net, sta, cha))\n",
    "    except:\n",
    "        print('pass station {} day {}'.format(sta,jday))\n",
    "    return(st)\n",
    "    \n",
    "# creates a df for each trace and append this df to a daily df\n",
    "# def create_df(datas, ti, freqs_names, df):\n",
    "#     datas = np.array(datas)\n",
    "#     time = [(ti+j*600).datetime for j in range(datas.shape[1])]\n",
    "#     df_tr = pd.DataFrame(zip(*datas), columns=freqs_names, index=pd.Series(time))\n",
    "#     df = pd.concat([df, df_tr])\n",
    "#     return(df)    \n",
    "\n",
    "def create_df(datas, ti, freqs_names, df):\n",
    "    datas = np.array(datas)\n",
    "    time = [(ti+j*600).datetime for j in range(datas.shape[1])]\n",
    "    df_tr = pd.DataFrame(zip(*datas), columns=freqs_names+['rms','rmes','pgv','pga'], index=pd.Series(time))\n",
    "    df = pd.concat([df, df_tr])\n",
    "    return(df) \n",
    "    \n",
    "# main function..............................................................................\n",
    "def tsfel_calc(jday, year, netstacha):   \n",
    "    ''' \n",
    "    calculate and store power in 10 min long time windows for different frequency bands\n",
    "    sensor measured ground velocity\n",
    "    freqs: list contains min and max frequency in Hz\n",
    "    dsar: float represents displacement (integration of)'''\n",
    "    \n",
    "    net = netstacha.split('-')[0]\n",
    "    sta = netstacha.split('-')[1]\n",
    "    cha = netstacha.split('-')[2]\n",
    "    \n",
    "#     file_path = '/data/wsd03/data_manuela/MtStHelens/RSAM_DSAR/tmp_{}/{}/'.format(year, sta)\n",
    "    file_path = './tmp_{}/{}/'.format(year, sta)\n",
    "    file_name = '{}_{}.csv'.format(sta,jday)\n",
    "        \n",
    "    if os.path.isfile(file_path+file_name):\n",
    "        print('file for {}-{} at {} already exist'.format(year,jday, netstacha))\n",
    "        pass\n",
    "    else:    \n",
    "        start_time = time.time()\n",
    "        freqs_names = ['rsam','mf','hf','dsar','ldsar', 'vsar']\n",
    "        df = pd.DataFrame(columns=freqs_names)\n",
    "        daysec = 24*3600\n",
    "\n",
    "        st = preprocessing(year,jday, net, sta, cha)\n",
    "\n",
    "        if len(st)>0: # if stream not empty\n",
    "    #         st.resample(50)\n",
    "            for tr in st:\n",
    "    #         tr = st[0]\n",
    "                datas = []\n",
    "                data = tr.data\n",
    "                samp_rate = tr.meta['sampling_rate']\n",
    "                ti = tr.meta['starttime']\n",
    "                # round start time to nearest 10 min increment\n",
    "                tiday = obspy.UTCDateTime(\"{:d}-{:02d}-{:02d} 00:00:00\".format(ti.year, ti.month, ti.day)) # date\n",
    "                ti = tiday+int(np.round((ti-tiday)/600))*600 # nearest 10 min to starttime\n",
    "                N = int(600*samp_rate)    # 10 minute windows in seconds\n",
    "                Nm = int(N*np.floor(len(data)/N)) # np.floor rounds always to the smaller number\n",
    "                # seconds per day (86400) * sampling rate (100) -> datapoints per day\n",
    "\n",
    "#                 datas = DSAR(data, samp_rate, datas, freqs_names, freqs, Nm, N)\n",
    "                X = tsfel.time_series_features_extractor(cfg, df)\n",
    "\n",
    "#                 df = create_df(datas, ti, freqs_names, df)\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                os.makedirs(file_path)\n",
    "                \n",
    "            X.to_csv(file_path + file_name, index=True, index_label='time')\n",
    "            print('One day tooks {} seconds.'.format(round(time.time()-start_time),3))\n",
    "        else:\n",
    "            print('empty stream station {} day {}'.format(sta,jday))\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54c97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations as string 'network-station-channel'\n",
    "s1  = 'UW-EDM-EHZ'\n",
    "s2  = 'UW-SHW-EHZ'\n",
    "s3  = 'UW-HSR-EHZ'\n",
    "s4  = 'UW-SOS-EHZ'\n",
    "s5  = 'UW-JUN-EHZ'\n",
    "s6  = 'UW-ELK-EHZ'\n",
    "s7  = 'UW-TDL-EHZ'\n",
    "s8  = 'UW-SUG-EHZ'\n",
    "s9  = 'UW-YEL-EHZ'\n",
    "s10 = 'UW-FL2-EHZ'\n",
    "s11 = 'UW-CDF-?HZ' #'UW-CDF-?H?' # eighter HHZ or EHZ\n",
    "\n",
    "s12 = 'UW-SEP-?HZ' #'UW-SEP-?H?'\n",
    "s13 = 'CC-SEP-?HZ' #'CC-SEP-?H?' # only one of the two SEP at the time & either EHZ or BHZ\n",
    "s14 = 'UW-STD-EHZ'\n",
    "s15 = 'CC-STD-BHZ'\n",
    "\n",
    "s16 = 'CC-VALT-BHZ' #'CC-VALT-BH?'\n",
    "s17 = 'CC-JRO-BHZ'\n",
    "s18 = 'CC-HOA-BHZ' #'CC-HOA-BH?'\n",
    "s19 = 'CC-LOO-BHZ' #'CC-LOO-BH?'\n",
    "s20 = 'CC-USFR-BHZ' #'CC-USFR-BH?'\n",
    "s21 = 'CC-NED-EHZ'\n",
    "s22 = 'CC-REM-BHZ' #'CC-REM-BH?'\n",
    "s23 = 'CC-SWFL-BHZ' #'CC-SWFL-BH?'\n",
    "s24 = 'CC-SFW2-BHZ' #'CC-SFW2-BH?'\n",
    "s25 = 'CC-MIDE-EHZ'\n",
    "s26 = 'CC-MIBL-EHZ'\n",
    "s27 = 'CC-BLIS-EHZ'\n",
    "s28 = 'CC-RAFT-EHZ'\n",
    "s29 = 'CC-SPN5-EHZ'\n",
    "s30 = 'CC-SEND-EHZ'\n",
    "\n",
    "list_stations = [s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,\n",
    "                 s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,s27,s28,s29,s30] # make a list of all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2580849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = tsfel.get_features_by_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d1b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":) year=2004, jday=100, net=UW, sta=EDM, cha=EHZ\n",
      "*** Feature extraction started ***\n",
      "60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='60'\n",
       "                  max='60',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  60\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n",
      "60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 6% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='4'\n",
       "                  max='60',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  4\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_stations = [s1]\n",
    "year = 2004\n",
    "jday = 100\n",
    "\n",
    "for netstacha in list_stations:\n",
    "    net = netstacha.split('-')[0]\n",
    "    sta = netstacha.split('-')[1]\n",
    "    cha = netstacha.split('-')[2]\n",
    "\n",
    "    file_path = '/data/wsd03/data_manuela/MtStHelens/RSAM_DSAR/tmp_{}/{}/'.format(year, sta)\n",
    "    file_name = 'tsfel{}_{}.csv'.format(sta,jday)\n",
    "\n",
    "    if os.path.isfile(file_path+file_name):\n",
    "        print('file for {}-{} at {} already exist'.format(year,jday, netstacha))\n",
    "        pass\n",
    "    else:    \n",
    "        start_time = time.time()\n",
    "        freqs_names = ['rsam','mf','hf','dsar','ldsar', 'vsar']\n",
    "        df = pd.DataFrame(columns=freqs_names)\n",
    "        daysec = 24*3600\n",
    "\n",
    "        st = preprocessing(year,jday, net, sta, cha)\n",
    "\n",
    "        if len(st)>0: # if stream not empty\n",
    "    #         st.resample(50)\n",
    "            for tr in st:\n",
    "    #         tr = st[0]\n",
    "                datas = []\n",
    "                data = tr.data\n",
    "                samp_rate = tr.meta['sampling_rate']\n",
    "                ti = tr.meta['starttime']\n",
    "                # round start time to nearest 10 min increment\n",
    "                tiday = obspy.UTCDateTime(\"{:d}-{:02d}-{:02d} 00:00:00\".format(ti.year, ti.month, ti.day)) # date\n",
    "                ti = tiday+int(np.round((ti-tiday)/600))*600 # nearest 10 min to starttime\n",
    "                N = int(600*samp_rate)    # 10 minute windows in seconds\n",
    "                Nm = int(N*np.floor(len(data)/N)) # np.floor rounds always to the smaller number\n",
    "                # seconds per day (86400) * sampling rate (100) -> datapoints per day\n",
    "\n",
    "    #                 datas = DSAR(data, samp_rate, datas, freqs_names, freqs, Nm, N)\n",
    "                cfg = tsfel.get_features_by_domain()\n",
    "                X = tsfel.time_series_features_extractor(cfg, data)\n",
    "\n",
    "    #                 df = create_df(datas, ti, freqs_names, df)\n",
    "\n",
    "    #             if not os.path.exists(file_path):\n",
    "    #                 os.makedirs(file_path)\n",
    "\n",
    "    #             df.to_csv(file_path + file_name, index=True, index_label='time')\n",
    "            print('One day tooks {} seconds.'.format(round(time.time()-start_time),3))\n",
    "        else:\n",
    "            print('empty stream station {} day {}'.format(sta,jday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = tr[0].stats.sampling_rate\n",
    "wlen = int(10 * 60 * fs)\n",
    "step =  wlen\n",
    "nwindow = int(np.floor(len(tr[0].data)/wlen))\n",
    "nmax = int(wlen*np.floor(len(tr[0].data)/wlen))\n",
    "print(nwindow,wlen,nmax)\n",
    "\n",
    "data = np.reshape(tr[0].data[:nmax],(nwindow,wlen))\n",
    "plt.plot(data)\n",
    "# plt.pcolormesh(data,vmin=-0.002,vmax=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fd42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = tsfel.get_features_by_domain()\n",
    "df=[]\n",
    "for i in range(nwindow):\n",
    "    if df is None:\n",
    "        df=tsfel.time_series_features_extractor(cfg, data[i,:], fs= fs, window_size=wlen)\n",
    "    else:\n",
    "        df.append(tsfel.time_series_features_extractor(cfg, data[i,:], fs= fs, window_size=wlen))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61697b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00242fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>0_FFT mean coefficient_0</th>\n",
       "      <th>0_FFT mean coefficient_1</th>\n",
       "      <th>0_FFT mean coefficient_2</th>\n",
       "      <th>0_FFT mean coefficient_3</th>\n",
       "      <th>0_FFT mean coefficient_4</th>\n",
       "      <th>0_FFT mean coefficient_5</th>\n",
       "      <th>0_FFT mean coefficient_6</th>\n",
       "      <th>0_FFT mean coefficient_7</th>\n",
       "      <th>0_FFT mean coefficient_8</th>\n",
       "      <th>...</th>\n",
       "      <th>0_Median diff</th>\n",
       "      <th>0_Negative turning points</th>\n",
       "      <th>0_Neighbourhood peaks</th>\n",
       "      <th>0_Peak to peak distance</th>\n",
       "      <th>0_Positive turning points</th>\n",
       "      <th>0_Signal distance</th>\n",
       "      <th>0_Slope</th>\n",
       "      <th>0_Sum absolute diff</th>\n",
       "      <th>0_Total energy</th>\n",
       "      <th>0_Zero crossing rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.019801e-13</td>\n",
       "      <td>2.158443e-11</td>\n",
       "      <td>2.619769e-12</td>\n",
       "      <td>3.958100e-13</td>\n",
       "      <td>4.600889e-14</td>\n",
       "      <td>4.631207e-14</td>\n",
       "      <td>6.760866e-14</td>\n",
       "      <td>5.769936e-14</td>\n",
       "      <td>2.922720e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.988124e-10</td>\n",
       "      <td>3260289.0</td>\n",
       "      <td>336662.0</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>3260288.0</td>\n",
       "      <td>8047374.0</td>\n",
       "      <td>1.187789e-17</td>\n",
       "      <td>1.557444</td>\n",
       "      <td>4.054075e-09</td>\n",
       "      <td>585739.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 390 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  0_FFT mean coefficient_0  0_FFT mean coefficient_1  \\\n",
       "0     0              1.019801e-13              2.158443e-11   \n",
       "\n",
       "   0_FFT mean coefficient_2  0_FFT mean coefficient_3  \\\n",
       "0              2.619769e-12              3.958100e-13   \n",
       "\n",
       "   0_FFT mean coefficient_4  0_FFT mean coefficient_5  \\\n",
       "0              4.600889e-14              4.631207e-14   \n",
       "\n",
       "   0_FFT mean coefficient_6  0_FFT mean coefficient_7  \\\n",
       "0              6.760866e-14              5.769936e-14   \n",
       "\n",
       "   0_FFT mean coefficient_8  ...  0_Median diff  0_Negative turning points  \\\n",
       "0              2.922720e-14  ...  -1.988124e-10                  3260289.0   \n",
       "\n",
       "   0_Neighbourhood peaks  0_Peak to peak distance  0_Positive turning points  \\\n",
       "0               336662.0                 0.000441                  3260288.0   \n",
       "\n",
       "   0_Signal distance       0_Slope  0_Sum absolute diff  0_Total energy  \\\n",
       "0          8047374.0  1.187789e-17             1.557444    4.054075e-09   \n",
       "\n",
       "   0_Zero crossing rate  \n",
       "0              585739.0  \n",
       "\n",
       "[1 rows x 390 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tmp_2004/EDM/EDM_100.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78ea7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
